---
    layout: post
    title: Perform model selection with hyperparameter tuning 
    description: nil
    summary: nil
    tags: nil
---


 <a target="_blank" href="https://docs.microsoft.com/en-us/learn/modules/perform-model-selection-with-hyperparameter-tuning/4-knowledge-check/"><i class="fas fa-external-link-alt"></i> </a>
 <img align="right" src="https://docs.microsoft.com/en-us/learn/achievements/perform-model-selection-with-hyperparameter-tuning.svg">
####  1. What is the likely cause when a supervised model makes predictions perfectly against all the training data, but fails against new data?


<i class='fas fa-check-square' style='color: Dodgerblue;'></i> &nbsp;&nbsp;Overfitting

<i class='far fa-square'></i> &nbsp;&nbsp;Underfitting

<i class='far fa-square'></i> &nbsp;&nbsp;Regularization
<br />
<br />
<br />

####  2. Which of the following statements best describes how the k-fold cross-validation splits the training data into the various folds?


<i class='far fa-square'></i> &nbsp;&nbsp;In k-fold cross-validation, the validation subset is always the same across all folds.

<i class='far fa-square'></i> &nbsp;&nbsp;In k-fold cross-validation, the training and validation subsets are created with random sampling of the training data with replacement.

<i class='fas fa-check-square' style='color: Dodgerblue;'></i> &nbsp;&nbsp;In k-fold cross-validation, each observation from the original training dataset has a chance to appear in both the training subset and the validation subset.
<br />
<br />
<br />

####  3. Which of the following is always true when using k-fold cross-validation?


<i class='far fa-square'></i> &nbsp;&nbsp;In k-fold cross-validation, the best performing fold is the selected model pipeline.

<i class='fas fa-check-square' style='color: Dodgerblue;'></i> &nbsp;&nbsp;In k-fold cross-validation, the best performing fold only identifies the winning pipeline.

<i class='far fa-square'></i> &nbsp;&nbsp;The k-fold cross-validation technique is used to fine-tune the machine learning algorithmâ€™s hyperparameters.
<br />
<br />
<br />
